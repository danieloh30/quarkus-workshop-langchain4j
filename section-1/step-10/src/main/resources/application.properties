quarkus.langchain4j.openai.api-key=${OPENAI_API_KEY}
quarkus.langchain4j.openai.chat-model.model-name=gpt-4o-mini

#--8<-- [start:logs]
quarkus.langchain4j.openai.chat-model.log-requests=true
quarkus.langchain4j.openai.chat-model.log-responses=true
#--8<-- [end:logs]

quarkus.langchain4j.openai.chat-model.temperature=1.0
quarkus.langchain4j.openai.chat-model.max-completion-tokens=1000
quarkus.langchain4j.openai.chat-model.frequency-penalty=0
quarkus.langchain4j.pgvector.dimension=384
rag.location=src/main/resources/rag
quarkus.langchain4j.embedding-model.provider=dev.langchain4j.model.embedding.onnx.bgesmallenq.BgeSmallEnQuantizedEmbeddingModel

#--8<-- [start:otel]
#Observability
quarkus.otel.logs.enabled=true
quarkus.otel.traces.enabled=true
%test.quarkus.observability.enabled=false
#--8<-- [start:otel]

#--8<-- [start:traces]
# quarkus.otel.exporter.otlp.traces.endpoint=http://localhost:4317
quarkus.otel.exporter.otlp.traces.headers=authorization=Bearer my_secret 
quarkus.log.console.format=%d{HH:mm:ss} %-5p traceId=%X{traceId}, parentId=%X{parentId}, spanId=%X{spanId}, sampled=%X{sampled} [%c{2.}] (%t) %s%e%n  
quarkus.datasource.jdbc.telemetry=true
#--8<-- [start:traces]